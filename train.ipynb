{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Piper Voice Training Notebook\n",
    "This notebook automates the process of training a Piper voice model, including:\n",
    "1. Dataset preprocessing\n",
    "2. Model training\n",
    "3. Model exporting\n",
    "4. Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies\n",
    "Ensure all required dependencies are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y python3-dev espeak-ng\n",
    "!pip install --upgrade pip wheel setuptools\n",
    "!pip install pytorch-lightning jupyterlab\n",
    "\n",
    "# Install Piper\n",
    "!git clone https://github.com/rhasspy/piper.git\n",
    "%cd piper/src/python\n",
    "!pip install -e .\n",
    "!bash build_monotonic_align.sh\n",
    "%cd ../../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Dataset\n",
    "Place your dataset in the `dataset` directory with the following structure:\n",
    "```\n",
    "dataset/\n",
    "├── metadata.csv\n",
    "├── wav/\n",
    "│   ├── 1.wav\n",
    "│   ├── 2.wav\n",
    "│   └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create dataset directory\n",
    "dataset_dir = \"dataset\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "# Example: Create metadata.csv and wav directory\n",
    "metadata_path = os.path.join(dataset_dir, \"metadata.csv\")\n",
    "wav_dir = os.path.join(dataset_dir, \"wav\")\n",
    "os.makedirs(wav_dir, exist_ok=True)\n",
    "\n",
    "# Example metadata.csv content (single speaker)\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    f.write(\"1|This is a test sentence.\\n\")\n",
    "    f.write(\"2|Another test sentence.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Preprocess Dataset\n",
    "Run the preprocessing script to generate `config.json` and `dataset.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m piper_train.preprocess \\\n",
    "  --language en-us \\\n",
    "  --input-dir {dataset_dir} \\\n",
    "  --output-dir training_dir \\\n",
    "  --dataset-format ljspeech \\\n",
    "  --single-speaker \\\n",
    "  --sample-rate 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the Model\n",
    "Train the Piper voice model using the preprocessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a pre-trained model checkpoint (e.g., lessac medium quality)\n",
    "!wget https://example.com/path/to/lessac/epoch=2164-step=1355540.ckpt -O lessac.ckpt\n",
    "\n",
    "# Train the model\n",
    "!python3 -m piper_train \\\n",
    "    --dataset-dir training_dir \\\n",
    "    --accelerator 'gpu' \\\n",
    "    --devices 1 \\\n",
    "    --batch-size 32 \\\n",
    "    --validation-split 0.0 \\\n",
    "    --num-test-examples 0 \\\n",
    "    --max_epochs 10000 \\\n",
    "    --resume_from_checkpoint lessac.ckpt \\\n",
    "    --checkpoint-epochs 1 \\\n",
    "    --precision 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Export the Model\n",
    "Export the trained model to ONNX format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest checkpoint\n",
    "import glob\n",
    "checkpoints = glob.glob(\"training_dir/lightning_logs/version_0/checkpoints/*.ckpt\")\n",
    "latest_checkpoint = checkpoints[-1]\n",
    "\n",
    "# Export to ONNX\n",
    "!python3 -m piper_train.export_onnx \\\n",
    "    {latest_checkpoint} \\\n",
    "    model.onnx\n",
    "\n",
    "# Copy config.json\n",
    "!cp training_dir/config.json model.onnx.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test the Model\n",
    "Test the exported model by generating audio from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test sentence\n",
    "test_sentence = \"This is a test sentence generated by Piper.\"\n",
    "\n",
    "# Generate audio\n",
    "!echo '{test_sentence}' | \\\n",
    "  piper -m model.onnx --output_file test.wav\n",
    "\n",
    "# Play the audio (requires IPython and sound playback support)\n",
    "from IPython.display import Audio\n",
    "Audio(\"test.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Monitor Training with TensorBoard\n",
    "Monitor training progress using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir training_dir/lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Export and Download the Model\n",
    "Export the trained model and provide download links for the ONNX model and JSON config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import json\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Define the source paths for the ONNX model and config\n",
    "onnx_source_path = \"model.onnx\"\n",
    "config_source_path = \"model.onnx.json\"\n",
    "\n",
    "# Define the destination paths for download\n",
    "onnx_destination_path = \"./piper_model.onnx\"\n",
    "config_destination_path = \"./piper_model.json\"\n",
    "\n",
    "# Copy the ONNX model and config to the current working directory\n",
    "shutil.copy(onnx_source_path, onnx_destination_path)\n",
    "shutil.copy(config_source_path, config_destination_path)\n",
    "\n",
    "# Define the JSON file content for Piper\n",
    "piper_json_data = {\n",
    "    \"dataset\": \"norman\",  # Update this with your dataset name\n",
    "    \"audio\": {\n",
    "        \"sample_rate\": 22050,  # Update this based on your model's sample rate\n",
    "        \"quality\": \"medium\"    # Update this based on your model's quality\n",
    "    },\n",
    "    \"espeak\": {\n",
    "        \"voice\": \"en\"  # Update this based on your model's espeak voice\n",
    "    },\n",
    "    \"language\": {\n",
    "        \"code\": \"en_US\",        # Update this based on your model's language\n",
    "        \"family\": \"en\",         # Language family\n",
    "        \"region\": \"US\",         # Region\n",
    "        \"name_native\": \"English\",  # Native language name\n",
    "        \"name_english\": \"English\", # English language name\n",
    "        \"country_english\": \"United States\"  # Country name in English\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"noise_scale\": 0.667,  # Noise scale for inference\n",
    "        \"length_scale\": 1.0,   # Length scale for inference\n",
    "        \"noise_w\": 0.8         # Noise width for inference\n",
    "    },\n",
    "    \"phoneme_type\": \"espeak\",  # Phoneme type (e.g., espeak or text)\n",
    "    \"phoneme_map\": {},         # Phoneme map (if applicable)\n",
    "    \"phoneme_id_map\": {\n",
    "        \" \": [3],  # Word separator\n",
    "        \"!\": [4],  # Exclamation mark\n",
    "        \"$\": [2],  # End of utterance\n",
    "        \"'\": [5],  # Single quote\n",
    "        \"(\": [6],  # Open parenthesis\n",
    "        \")\": [7],  # Close parenthesis\n",
    "        \",\": [8],  # Comma\n",
    "        \"-\": [9],  # Hyphen\n",
    "        \".\": [10],  # Period\n",
    "        \"0\": [130],  # Number 0\n",
    "        \"1\": [131],  # Number 1\n",
    "        \"2\": [132],  # Number 2\n",
    "        \"3\": [133],  # Number 3\n",
    "        \"4\": [134],  # Number 4\n",
    "        \"5\": [135],  # Number 5\n",
    "        \"6\": [136],  # Number 6\n",
    "        \"7\": [137],  # Number 7\n",
    "        \"8\": [138],  # Number 8\n",
    "        \"9\": [139],  # Number 9\n",
    "        \":\": [11],  # Colon\n",
    "        \";\": [12],  # Semicolon\n",
    "        \"?\": [13],  # Question mark\n",
    "        \"^\": [1],  # Beginning of utterance\n",
    "        \"_\": [0],  # Padding\n",
    "        \"a\": [14],  # Phoneme a\n",
    "        \"b\": [15],  # Phoneme b\n",
    "        \"c\": [16],  # Phoneme c\n",
    "        \"d\": [17],  # Phoneme d\n",
    "        \"e\": [18],  # Phoneme e\n",
    "        \"f\": [19],  # Phoneme f\n",
    "        \"g\": [20],  # Phoneme g\n",
    "        \"h\": [21],  # Phoneme h\n",
    "        \"i\": [22],  # Phoneme i\n",
    "        \"j\": [23],  # Phoneme j\n",
    "        \"k\": [24],  # Phoneme k\n",
    "        \"l\": [25],  # Phoneme l\n",
    "        \"m\": [26],  # Phoneme m\n",
    "        \"n\": [27],  # Phoneme n\n",
    "        \"o\": [28],  # Phoneme o\n",
    "        \"p\": [29],  # Phoneme p\n",
    "        \"q\": [30],  # Phoneme q\n",
    "        \"r\": [31],  # Phoneme r\n",
    "        \"s\": [32],  # Phoneme s\n",
    "        \"t\": [33],  # Phoneme t\n",
    "        \"u\": [34],  # Phoneme u\n",
    "        \"v\": [35],  # Phoneme v\n",
    "        \"w\": [36],  # Phoneme w\n",
    "        \"x\": [37],  # Phoneme x\n",
    "        \"y\": [38],  # Phoneme y\n",
    "        \"z\": [39]   # Phoneme z\n",
    "    },\n",
    "    \"num_symbols\": 256,  # Number of phonemes in the model\n",
    "    \"num_speakers\": 1,   # Number of speakers in the model\n",
    "    \"speaker_id_map\": {},  # Speaker ID map (if applicable)\n",
    "    \"piper_version\": \"1.0.0\"  # Piper version\n",
    "}\n",
    "\n",
    "# Write the JSON file\n",
    "with open(config_destination_path, \"w\") as json_file:\n",
    "    json.dump(piper_json_data, json_file, indent=2)\n",
    "\n",
    "# Generate download links for both files\n",
    "print(\"Download your files:\")\n",
    "print(\"ONNX Model:\")\n",
    "display(FileLink(onnx_destination_path))\n",
    "print(\"\\nJSON Config:\")\n",
    "display(FileLink(config_destination_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
